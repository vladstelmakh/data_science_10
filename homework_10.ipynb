{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7QUwTyvipWK0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Частина 1"
      ],
      "metadata": {
        "id": "KWQX84vdxkdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантаження та підготовка даних\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Нормалізація зображень\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Зміна розміру зображень для згорткової мережі\n",
        "train_images = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# One-hot кодування міток\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "# Створення моделі\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy',Precision(), Recall(), AUC()])\n",
        "\n",
        "# Навчання моделі\n",
        "history = model.fit(train_images, train_labels_one_hot, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1DTG9BwxjDt",
        "outputId": "5b6b534c-8c76-4dbf-e783-f8c8443b504b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.7166 - accuracy: 0.7742 - precision_8: 0.8569 - recall_8: 0.7021 - auc_8: 0.9789 - val_loss: 0.5145 - val_accuracy: 0.8398 - val_precision_8: 0.8757 - val_recall_8: 0.8040 - val_auc_8: 0.9883\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.4672 - accuracy: 0.8538 - precision_8: 0.8852 - recall_8: 0.8231 - auc_8: 0.9900 - val_loss: 0.3957 - val_accuracy: 0.8748 - val_precision_8: 0.9012 - val_recall_8: 0.8538 - val_auc_8: 0.9927\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.3996 - accuracy: 0.8735 - precision_8: 0.8969 - recall_8: 0.8499 - auc_8: 0.9922 - val_loss: 0.3670 - val_accuracy: 0.8819 - val_precision_8: 0.9043 - val_recall_8: 0.8632 - val_auc_8: 0.9934\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.3678 - accuracy: 0.8828 - precision_8: 0.9050 - recall_8: 0.8614 - auc_8: 0.9932 - val_loss: 0.3425 - val_accuracy: 0.8942 - val_precision_8: 0.9162 - val_recall_8: 0.8775 - val_auc_8: 0.9942\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.3457 - accuracy: 0.8902 - precision_8: 0.9101 - recall_8: 0.8733 - auc_8: 0.9941 - val_loss: 0.3328 - val_accuracy: 0.8928 - val_precision_8: 0.9123 - val_recall_8: 0.8764 - val_auc_8: 0.9944\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.3290 - accuracy: 0.8959 - precision_8: 0.9147 - recall_8: 0.8786 - auc_8: 0.9946 - val_loss: 0.3167 - val_accuracy: 0.8981 - val_precision_8: 0.9167 - val_recall_8: 0.8832 - val_auc_8: 0.9952\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.3168 - accuracy: 0.8995 - precision_8: 0.9168 - recall_8: 0.8842 - auc_8: 0.9951 - val_loss: 0.3153 - val_accuracy: 0.8995 - val_precision_8: 0.9171 - val_recall_8: 0.8852 - val_auc_8: 0.9950\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.3054 - accuracy: 0.9043 - precision_8: 0.9199 - recall_8: 0.8895 - auc_8: 0.9954 - val_loss: 0.3175 - val_accuracy: 0.9015 - val_precision_8: 0.9136 - val_recall_8: 0.8926 - val_auc_8: 0.9941\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.2932 - accuracy: 0.9081 - precision_8: 0.9238 - recall_8: 0.8947 - auc_8: 0.9957 - val_loss: 0.3216 - val_accuracy: 0.8982 - val_precision_8: 0.9169 - val_recall_8: 0.8851 - val_auc_8: 0.9948\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.2866 - accuracy: 0.9111 - precision_8: 0.9259 - recall_8: 0.8967 - auc_8: 0.9959 - val_loss: 0.2884 - val_accuracy: 0.9126 - val_precision_8: 0.9285 - val_recall_8: 0.8976 - val_auc_8: 0.9958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(test_images[-1500:], test_labels_one_hot[-1500:])\n",
        "\n",
        "print(f\"Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {test_precision:.2f}\")\n",
        "print(f\"Recall: {test_recall:.2f}\")\n",
        "print(f\"AUC: {test_auc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsK1Jsm1q5_I",
        "outputId": "3f135eaa-d02f-469a-9a0a-5546df578da1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 8ms/step - loss: 0.2908 - accuracy: 0.9120 - precision_8: 0.9273 - recall_8: 0.8933 - auc_8: 0.9960\n",
            "Accuracy: 91.20%\n",
            "Precision: 0.93\n",
            "Recall: 0.89\n",
            "AUC: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the metrics"
      ],
      "metadata": {
        "id": "4QGTqWntxpCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(test_images[-1500:], test_labels_one_hot[-1500:])\n",
        "\n",
        "print(f\"Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {test_precision:.2f}\")\n",
        "print(f\"Recall: {test_recall:.2f}\")\n",
        "print(f\"AUC: {test_auc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zCZPeq_xFC-",
        "outputId": "1aaa9390-5660-4393-fed0-ed237eaf54b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.8387 - precision_30: 0.8767 - recall_30: 0.8107 - auc_30: 0.9885\n",
            "Accuracy: 83.87%\n",
            "Precision: 0.88\n",
            "Recall: 0.81\n",
            "AUC: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Частина 2"
      ],
      "metadata": {
        "id": "WpJ4HZZmxsct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "L1G7UVL0LMis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "5ayH9r8vchUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_rgb(img):\n",
        "    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n",
        "    img_rgb = np.asarray(np.dstack((img, img, img)), dtype=np.uint8)\n",
        "    return img_rgb"
      ],
      "metadata": {
        "id": "hSniW-t7cgFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_rgb = [to_rgb(img) for img in training_images]\n",
        "test_images_rgb = [to_rgb(img) for img in test_images]"
      ],
      "metadata": {
        "id": "MDOi-fSJcin-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_rgb = np.array(training_images_rgb) / 255.0\n",
        "test_images_rgb = np.array(test_images_rgb) / 255.0"
      ],
      "metadata": {
        "id": "B1alX9TIcj62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_labels_one_hot = to_categorical(training_labels, num_classes=10)\n",
        "test_labels_one_hot = to_categorical(test_labels, num_classes=10)"
      ],
      "metadata": {
        "id": "zMQgaXFhclhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(input_shape=(32, 32, 3), weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "cS_BFbshcne2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg.output)\n",
        "prediction = Dense(10, activation='softmax')(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o0EVoKtucrim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',  # Using categorical_crossentropy since we have one-hot encoded labels\n",
        "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])"
      ],
      "metadata": {
        "id": "ztRP65ypctgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model1.fit(training_images_rgb, training_labels_one_hot, epochs=5, batch_size=32)  # Ensure batch_size aligns with your data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C0A0-30cYrn",
        "outputId": "249de427-4884-4750-9e20-ded108e51c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 626s 333ms/step - loss: 0.7094 - accuracy: 0.7710 - precision_1: 0.8802 - recall_1: 0.6309 - auc_1: 0.9750\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 619s 330ms/step - loss: 0.4928 - accuracy: 0.8278 - precision_1: 0.8818 - recall_1: 0.7687 - auc_1: 0.9864\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 621s 331ms/step - loss: 0.4511 - accuracy: 0.8396 - precision_1: 0.8861 - recall_1: 0.7912 - auc_1: 0.9883\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 621s 331ms/step - loss: 0.4284 - accuracy: 0.8476 - precision_1: 0.8896 - recall_1: 0.8043 - auc_1: 0.9893\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 620s 331ms/step - loss: 0.4138 - accuracy: 0.8514 - precision_1: 0.8905 - recall_1: 0.8118 - auc_1: 0.9899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cecd9838280>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = model1.evaluate(test_images_rgb[-1500:], test_labels_one_hot[-1500:])\n",
        "\n",
        "print(f\"Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {test_precision:.2f}\")\n",
        "print(f\"Recall: {test_recall:.2f}\")\n",
        "print(f\"AUC: {test_auc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9LmoH60pApg",
        "outputId": "54345cdd-ef60-49ca-9585-f114028cd2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 16s 338ms/step - loss: 0.4656 - accuracy: 0.8333 - precision_1: 0.8681 - recall_1: 0.7940 - auc_1: 0.9865\n",
            "Accuracy: 83.33%\n",
            "Precision: 0.87\n",
            "Recall: 0.79\n",
            "AUC: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подібні загальні показники: Обидві мережі показують порівнянно високі показники точності, точності (precision), чутливості (recall) та площі під кривою (AUC). Це свідчить про те, що обидві моделі досить ефективно класифікують зображення за допомогою даних Fashion MNIST."
      ],
      "metadata": {
        "id": "sGjdfw8IwK0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Незважаючи на трохи нижчу продуктивність, використання передтренованих мереж, як VGG16, може бути корисним у випадках обмежених обчислювальних ресурсів або коли потрібно швидке розгортання моделі. Вони також можуть бути корисними при роботі з дуже складними наборами даних, де потрібно вже передтреноване розуміння базових зображень."
      ],
      "metadata": {
        "id": "08MxiBNowLZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "У підсумку, обидві моделі показали себе досить ефективними, але   CNN злегка перевершила VGG16, що демонструє важливість специфічної настройки архітектури для конкретних даних та завдань."
      ],
      "metadata": {
        "id": "XhndrAruwcKh"
      }
    }
  ]
}